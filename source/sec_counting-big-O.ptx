<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec_counting-big-O" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Complexity and Big-O Notation</title>

  <introduction>
    <p>In this section we apply our knowledge of looping and counting 
    to develop the notion of big-O notation. We'll look at functions 
    which accept an array as input and explore the growth in the number
    of operations run during function execution as the size of the 
    input array grows. In particular, we'll see applications which are 
    <m>O\left(1\right)</m>, <m>O\left(n\right)</m>, <m>O\left(n^2\right)</m>, and 
    <m>O\left(n^3\right)</m>. 
    </p>

    <p>We'll consider only run-time complexity in this section, though 
    students should also know that space-complexity is a competing 
    concern when writing code to solve problems. Students in computing 
    disciplines will encounter both run-time- and space-complexity 
    throughout their studies.
    </p>
  </introduction>

  <p><em>About.</em> In this section, it is necessary to provide 
  definitions of example functions. The functions are not written in 
  any particular language -- in fact, most won't work in <em>any</em> 
  language as you see them written here. Instead, the functions are 
  provided via some pseudocode -- something about halfway between 
  human preferrable and computer readable. Since we are working with 
  arrays, it is useful to have some convention about how to access 
  individual array elements. Throughout this section, we use <c>
  myArray[0]</c> to access the element in the left-most slot of 
  the <c>myArray</c> object. We use <c>myArray[i]</c> 
  to access the element in the <m>i^{th}</m> slot of <c>myArray
  </c>, remembering that the left-most item occupies the 
  <m>0^{th}</m> slot of <c>myArray</c>.
  </p>

  <p>Indexing from 0 may seem awkward to those of you who are just 
  beginning your computing careers, but this is the case for many 
  of the most popular computing languages. For this reason, we adopt
  0-based indexing here.
  </p>

    <exercise exercise-customization="inline" exercise-interactive="static">
        <title>Operations to Return First Element</title><introduction>
    	<p>Answer the following.
    	</p>
    </introduction><myopenmath problem="982380" />
	</exercise>

    <exercise exercise-customization="inline" exercise-interactive="static">
        <title>Operations to Sum First Five Elements</title><introduction>
    	<p>Answer the following.
    	</p>
    </introduction><myopenmath problem="982398" />
	</exercise>

    <exercise exercise-customization="inline" exercise-interactive="static">
        <title>Operations to Sum First Elements</title><introduction>
    	<p>Answer the following.
    	</p>
    </introduction><myopenmath problem="982400" />
	</exercise>

    <exercise exercise-customization="inline" exercise-interactive="static">
        <title>Operations to Sum All Elements</title><introduction>
    	<p>Answer the following.
    	</p>
    </introduction><myopenmath problem="982404" />
	</exercise>

  <p> Note that in the first three interactive problems above, the size
  of the input array didn't matter. That is, number of operations 
  required to arrive at the value to be returned did not depend on the 
  length of the input array. If you didn't notice that on your own, try 
  regenerating new versions of the embedded examples and working through 
  the examples again. In the final example, however, the number of 
  operations required to complete before arriving at the value to be 
  returned did depend on the length of the input array. Input arrays with 
  more elements require more calculations, and so it should be expected 
  that, as this <c>sum_array_values()</c> function is applied to 
  larger and larger arrays, it takes longer to run. How much longer 
  run-time should we expect if the length of the input array were to, 
  let's say, double in length? Should we expect the function to take 
  approximately twice as long? More time? Less that that? How can we 
  tell? This is the job of <em>big-O</em> notation.
  </p> 

  <p>Consider a routine which takes an array as input and then produces 
  some output. The run-time complexity of the algorithm describes the 
  <em>order</em> of the number of operations to be done in transforming 
  the input array into the output, as a function of the length of the 
  input array. Traditionally, the run-time complexity has been written 
  using big-O notation, which looks like <m>O\left(f\left(n\right)\right)</m>,
  where <m>f\left(n\right)</m> is a function of the length of the 
  input array. We'll see some examples below.
  </p>

  	<example xml:id = "return-first"> 
        <title>Run-Time Complexity 1</title>
		<p> Consider the routine below, which takes in an array as input 
        and returns the value of the first element of the array. Describe 
        the run-time of the routine as a function of the size of the 
        input <c>array</c>.</p>			
		<md>
		<mrow>\texttt{def return_first(array):}</mrow>
		<mrow>~~\texttt{return array[0]}</mrow> 
		</md>
        <solution> Note that the function immediately returns the first 
        element of the array, regardless of the size of the input array. 
        There is a single operation being done here, no matter what 
        non-empty array is supplied as the input. This means that the 
        routine in question has constant runtime. We say that the
        routine is <m>O\left(1\right)</m>. 
        </solution>
	</example>

    Let's see another example in which more than just a single operation 
    is required to transform the input array into the output.

    <example xml:id = "return-sum-first-two"> 
        <title>Run-Time Complexity 2</title>
		<p> Consider the routine below, which takes in an array as input 
        and returns the sum of the first two array elements. Describe 
        the run-time of the routine as a function of the size of the 
        input <c>array</c>.</p>			
		<md>
		<mrow>\texttt{def sum_first_two(array):}</mrow>
		<mrow>~~\texttt{a = array[0]}</mrow>
        <mrow>~~\texttt{b = array[1]}</mrow>
        <mrow>~~\texttt{total = a + b}</mrow>
        <mrow>~~\texttt{return total}</mrow> 
		</md>
        <solution> Note that the routine uses three operations in order 
        to transform the input <c>array</c> into the value which is 
        returned. First, the item in <c>array[0]</c> is stored in the 
        variable <m>a</m>. Next, the intem in <c>array[1]</c> is stored 
        in the variable <m>b</m>. Finally, the sum, <m>a + b</m> is 
        stored in the <c>total</c> variable, which is the value to be 
        returned. Three operations are being completed here, so we 
        might say that this routine has run-time complexity 
        <m>O\left(3\right)</m>. The attentive reader may ask why this 
        routine is not <m>O\left(4\right)</m> because of the <c>return</c>
        statement. In short, we shouldn't waste time making a distinction 
        because, regardless of whether we consider <c>return</c>ing a 
        value to be an operation or not, this routine has <em>constant</em> 
        run-time. That is, this routine is also <m>O\left(1\right)</m>. 
        </solution>
	</example>

    <p> We saw in the previous example that there is no distinction made 
    between <m>O\left(1\right)</m> and <m>O\left(3\right)</m>, or even 
    <m>O\left(10^6\right)</m>, for that matter. All of these denote 
    constant run-time, and so their big-O description of complexity is 
    <m>O\left(1\right)</m>. 
    </p>

    <p>Let's see how the run-time complexity grows for some more 
    interesting functions in the examples below.</p>
</section>

